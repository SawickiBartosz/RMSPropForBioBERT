{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from Optimizer.RMSProp import RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "optimizer = RMSProp(name=\"my_optim\", beta=0.9)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=10000, random_state=123)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.losses import BinaryCrossentropy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(20, activation=\"relu\", name=\"layer1\"),\n",
    "    layers.Dense(3, activation=\"relu\", name=\"layer2\"),\n",
    "    layers.Dense(1, activation=\"softmax\", name=\"layer3\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=BinaryCrossentropy(), metrics=BinaryCrossentropy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "157/157 [==============================] - 1s 1ms/step - loss: 0.5958 - binary_crossentropy: 0.5949\n",
      "Epoch 2/200\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3536 - binary_crossentropy: 0.3531\n",
      "Epoch 3/200\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2138 - binary_crossentropy: 0.2133\n",
      "Epoch 4/200\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1648 - binary_crossentropy: 0.1649\n",
      "Epoch 5/200\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1463 - binary_crossentropy: 0.1461\n",
      "Epoch 6/200\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1370 - binary_crossentropy: 0.1369\n",
      "Epoch 7/200\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1318 - binary_crossentropy: 0.1325\n",
      "Epoch 8/200\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1287 - binary_crossentropy: 0.1281\n",
      "Epoch 9/200\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1262 - binary_crossentropy: 0.1257\n",
      "Epoch 10/200\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1247 - binary_crossentropy: 0.1245\n",
      "Epoch 11/200\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1235 - binary_crossentropy: 0.1240\n",
      "Epoch 12/200\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1221 - binary_crossentropy: 0.1221\n",
      "Epoch 13/200\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1211 - binary_crossentropy: 0.1212\n",
      "Epoch 14/200\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1201 - binary_crossentropy: 0.1196\n",
      "Epoch 15/200\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1193 - binary_crossentropy: 0.1189\n",
      "Epoch 16/200\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1187 - binary_crossentropy: 0.1182\n",
      "Epoch 17/200\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1178 - binary_crossentropy: 0.1176\n",
      "Epoch 18/200\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1173 - binary_crossentropy: 0.1171\n",
      "Epoch 19/200\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1168 - binary_crossentropy: 0.1167\n",
      "Epoch 20/200\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1158 - binary_crossentropy: 0.1154\n",
      "Epoch 21/200\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1153 - binary_crossentropy: 0.1149\n",
      "Epoch 22/200\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1150 - binary_crossentropy: 0.1146\n",
      "Epoch 23/200\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1145 - binary_crossentropy: 0.1145\n",
      "Epoch 24/200\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1137 - binary_crossentropy: 0.1142\n",
      "Epoch 25/200\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1139 - binary_crossentropy: 0.1134\n",
      "Epoch 26/200\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1132 - binary_crossentropy: 0.1130\n",
      "Epoch 27/200\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1126 - binary_crossentropy: 0.1126\n",
      "Epoch 28/200\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1126 - binary_crossentropy: 0.1125\n",
      "Epoch 29/200\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1119 - binary_crossentropy: 0.1120\n",
      "Epoch 30/200\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1117 - binary_crossentropy: 0.1115\n",
      "Epoch 31/200\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1108 - binary_crossentropy: 0.1104\n",
      "Epoch 32/200\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1110 - binary_crossentropy: 0.1106\n",
      "Epoch 33/200\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1103 - binary_crossentropy: 0.1098\n",
      "Epoch 34/200\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1103 - binary_crossentropy: 0.1101\n",
      "Epoch 35/200\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1101 - binary_crossentropy: 0.1103\n",
      "Epoch 36/200\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1097 - binary_crossentropy: 0.1098\n",
      "Epoch 37/200\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1093 - binary_crossentropy: 0.1088\n",
      "Epoch 38/200\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1092 - binary_crossentropy: 0.1090\n",
      "Epoch 39/200\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1086 - binary_crossentropy: 0.1084\n",
      "Epoch 40/200\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1082 - binary_crossentropy: 0.1081\n",
      "Epoch 41/200\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1083 - binary_crossentropy: 0.1081\n",
      "Epoch 42/200\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1081 - binary_crossentropy: 0.1079\n",
      "Epoch 43/200\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1075 - binary_crossentropy: 0.1072\n",
      "Epoch 44/200\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1075 - binary_crossentropy: 0.1075\n",
      "Epoch 45/200\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1070 - binary_crossentropy: 0.1068\n",
      "Epoch 46/200\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1071 - binary_crossentropy: 0.1067\n",
      "Epoch 47/200\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1067 - binary_crossentropy: 0.1084\n",
      "Epoch 48/200\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1066 - binary_crossentropy: 0.1062\n",
      "Epoch 49/200\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1060 - binary_crossentropy: 0.1062\n",
      "Epoch 50/200\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1059 - binary_crossentropy: 0.1064\n",
      "Epoch 51/200\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1059 - binary_crossentropy: 0.1059\n",
      "Epoch 52/200\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1059 - binary_crossentropy: 0.1057\n",
      "Epoch 53/200\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1051 - binary_crossentropy: 0.1058\n",
      "Epoch 54/200\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1051 - binary_crossentropy: 0.1054\n",
      "Epoch 55/200\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1047 - binary_crossentropy: 0.1043\n",
      "Epoch 56/200\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1045 - binary_crossentropy: 0.1043\n",
      "Epoch 57/200\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1042 - binary_crossentropy: 0.1039\n",
      "Epoch 58/200\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1039 - binary_crossentropy: 0.1037\n",
      "Epoch 59/200\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1037 - binary_crossentropy: 0.1035\n",
      "Epoch 60/200\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1035 - binary_crossentropy: 0.1033\n",
      "Epoch 61/200\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1036 - binary_crossentropy: 0.1033\n",
      "Epoch 62/200\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1031 - binary_crossentropy: 0.1027\n",
      "Epoch 63/200\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1029 - binary_crossentropy: 0.1025\n",
      "Epoch 64/200\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1026 - binary_crossentropy: 0.1023\n",
      "Epoch 65/200\n",
      "136/157 [========================>.....] - ETA: 0s - loss: 0.1048 - binary_crossentropy: 0.1048"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m200\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Studies\\DataScience-1sem\\OptimizationInDataAnalysis\\RMSPropForBioBERT\\optimization_venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32mE:\\Studies\\DataScience-1sem\\OptimizationInDataAnalysis\\RMSPropForBioBERT\\optimization_venv\\lib\\site-packages\\keras\\engine\\training.py:1695\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1692\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstop_training:\n\u001B[0;32m   1693\u001B[0m                 \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m-> 1695\u001B[0m logs \u001B[38;5;241m=\u001B[39m \u001B[43mtf_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msync_to_numpy_or_python_type\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1696\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m logs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1697\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1698\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnexpected result of `train_function` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1699\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(Empty logs). Please use \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1703\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124missue/bug to `tf.keras`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1704\u001B[0m     )\n",
      "File \u001B[1;32mE:\\Studies\\DataScience-1sem\\OptimizationInDataAnalysis\\RMSPropForBioBERT\\optimization_venv\\lib\\site-packages\\keras\\utils\\tf_utils.py:680\u001B[0m, in \u001B[0;36msync_to_numpy_or_python_type\u001B[1;34m(tensors)\u001B[0m\n\u001B[0;32m    677\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m t\n\u001B[0;32m    678\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39mndim(t) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m t\n\u001B[1;32m--> 680\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_structure\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_to_single_numpy_or_python_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Studies\\DataScience-1sem\\OptimizationInDataAnalysis\\RMSPropForBioBERT\\optimization_venv\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001B[0m, in \u001B[0;36mmap_structure\u001B[1;34m(func, *structure, **kwargs)\u001B[0m\n\u001B[0;32m    913\u001B[0m flat_structure \u001B[38;5;241m=\u001B[39m (flatten(s, expand_composites) \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m structure)\n\u001B[0;32m    914\u001B[0m entries \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mflat_structure)\n\u001B[0;32m    916\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pack_sequence_as(\n\u001B[1;32m--> 917\u001B[0m     structure[\u001B[38;5;241m0\u001B[39m], [func(\u001B[38;5;241m*\u001B[39mx) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m entries],\n\u001B[0;32m    918\u001B[0m     expand_composites\u001B[38;5;241m=\u001B[39mexpand_composites)\n",
      "File \u001B[1;32mE:\\Studies\\DataScience-1sem\\OptimizationInDataAnalysis\\RMSPropForBioBERT\\optimization_venv\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    913\u001B[0m flat_structure \u001B[38;5;241m=\u001B[39m (flatten(s, expand_composites) \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m structure)\n\u001B[0;32m    914\u001B[0m entries \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mflat_structure)\n\u001B[0;32m    916\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pack_sequence_as(\n\u001B[1;32m--> 917\u001B[0m     structure[\u001B[38;5;241m0\u001B[39m], [\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m entries],\n\u001B[0;32m    918\u001B[0m     expand_composites\u001B[38;5;241m=\u001B[39mexpand_composites)\n",
      "File \u001B[1;32mE:\\Studies\\DataScience-1sem\\OptimizationInDataAnalysis\\RMSPropForBioBERT\\optimization_venv\\lib\\site-packages\\keras\\utils\\tf_utils.py:673\u001B[0m, in \u001B[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001B[1;34m(t)\u001B[0m\n\u001B[0;32m    670\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_to_single_numpy_or_python_type\u001B[39m(t):\n\u001B[0;32m    671\u001B[0m     \u001B[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001B[39;00m\n\u001B[0;32m    672\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(t, tf\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[1;32m--> 673\u001B[0m         t \u001B[38;5;241m=\u001B[39m \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    674\u001B[0m     \u001B[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001B[39;00m\n\u001B[0;32m    675\u001B[0m     \u001B[38;5;66;03m# as-is.\u001B[39;00m\n\u001B[0;32m    676\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(t, (np\u001B[38;5;241m.\u001B[39mndarray, np\u001B[38;5;241m.\u001B[39mgeneric)):\n",
      "File \u001B[1;32mE:\\Studies\\DataScience-1sem\\OptimizationInDataAnalysis\\RMSPropForBioBERT\\optimization_venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1160\u001B[0m, in \u001B[0;36m_EagerTensorBase.numpy\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1137\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001B[39;00m\n\u001B[0;32m   1138\u001B[0m \n\u001B[0;32m   1139\u001B[0m \u001B[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1157\u001B[0m \u001B[38;5;124;03m    NumPy dtype.\u001B[39;00m\n\u001B[0;32m   1158\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1159\u001B[0m \u001B[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001B[39;00m\n\u001B[1;32m-> 1160\u001B[0m maybe_arr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_numpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m   1161\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m maybe_arr\u001B[38;5;241m.\u001B[39mcopy() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(maybe_arr, np\u001B[38;5;241m.\u001B[39mndarray) \u001B[38;5;28;01melse\u001B[39;00m maybe_arr\n",
      "File \u001B[1;32mE:\\Studies\\DataScience-1sem\\OptimizationInDataAnalysis\\RMSPropForBioBERT\\optimization_venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1126\u001B[0m, in \u001B[0;36m_EagerTensorBase._numpy\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1124\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_numpy\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m   1125\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1126\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_numpy_internal\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1127\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_status_to_exception(e) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=200, batch_size=64)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
